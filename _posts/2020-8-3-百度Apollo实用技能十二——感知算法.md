---
title: 百度Apollo——感知算法
tags:
  - 百度
  - 无人驾驶
---

# Apollo 感知算法

### 点云感知

- 点云障碍物感知的主要任务是感知障碍物的位置、大小、类别、朝向、轨迹、速度等，核心是点云检测分割技术，可以用启发式算法NCut和深度学习算法CNNSeg完成
- 启发式算法NCut
  - Ncut算法的基本思想是基于空间平滑性假设，即空间上接近的点来自同一个障碍物
  - 根据预处理后的点云构建加权图G=(V, E, W)
  - 将点云分割转换为图分割的问题，可以利用图聚类的算法求解，最终求解的每一个cluster就代表一个障碍物
  - 该算法的优点是解释性好，缺点是分割规则过于简单
- 深度学习算法CNNSeg
  - 主要思想是利用卷积神经网络来处理激光雷达捕获的点云数据，并对点云中的目标进行识别
  - 深度学习是数据驱动的，它把人工构造特征这一任务交给机器和算法去完成
  - 算法研发的历程：
    - 将所有点云都投到前视图（投影面是一个圆柱面）来构造特征，将点云问题转化为矩阵问题，进而使用深度学习进行处理
    - 借助自采集车队，采集更多的实际数据，并且扩展数据视角，制作俯视图，通过将俯视图+前视图相结合的方式进行训练
    - 经过多次实验，发现基于俯视图的Segmentation方法效果最好
    - 因为俯视图没有高度信息，因此我们把前视图和Camara图像加进来进行辅助检查，利用Lidar的测距准和Camera识别准优势完成了Middle-Level Fusion方法，该方法使用俯视图提取Proposal，利用前视图和光学图像辅助进行更加精准的位置回归

### 视觉感知

- 视觉感知最早从ADAS发展而来
- ADAS算法相对轻量，采用人工构造的特征和浅层分类器的方式实现辅助驾驶，该方法目前已经难满足自动驾驶的需求
- 随着深度学习技术的发展，尤其是在视觉领域的巨大成功，视觉感知的主流技术路线已经变为“深度学习+后处理计算”的方法
- 但该方法带来了以下几个变化
  - 第一是要求计算硬件升级
  - 第二是数据的需求量大增
  - 第三是如何评估保证安全性
- 面向自动驾驶的深度学习算法具有以下几个特点：
  - 2D感知向3D感知渗透，模型输出更丰富（后处理需要的3D信息、跟踪信息、属性信息等都会放在CNN中进行学习）
  - 环视能力构建（传统方法靠一个Camera完成前向检测、碰撞检测、车道线检测。无人驾驶需要环视）
  - 感知+定位+地图紧密结合
- 深度学习：CNN检测
  - CNN检测是深度学习里一个十分火热的应用，从最开始的AlexNet,VggNet到ResNet等，持续提高了ImageNet图像检测的精度
  - 目前发表的大部分关于检测的成果都是面向计算机视觉应用的，与自动驾驶领域的检测还有很大的区别
  - 自动驾驶中的检测模型需要输出的信息更多，包括障碍物的尺寸、朝向
  - 同时自动驾驶还需要考虑时序性。我们称之为局部的End-to-End
  - 检测、2D到3D转换、跟踪三步是自动驾驶视觉感知的组成，后面两步都由CNN来学习，减少人工干预
  - 自动驾驶需要针对不同的障碍物特征（车道线，道路边界，定位元素）进行识别，如果分别由专用模型处理，整个处理流程太长，无法满足要求，因此需要做多任务的识别和网络结构的适配
  - 除了障碍物级别的输出以外，还需了解速度类别朝向等问题，例如车尾灯状态，车门开闭状态
- 深度学习：CNN分割
  - 分割（Segmentation）与detection在本质上是一样的，是对一个目标的不同力度的刻画
  - 分割是一种更细粒度刻画物体边界信息的检测方法，不再是画框，而是进行边缘分割
- 后处理计算
  - 一个完整的系统除了深度学习模型，还需要做一些后处理，后处理是直接针对下游模块，对后续的影响比较直接，后处理主要分为三个部分
  - 第一是2D-to-3D的几何计算，2D到3D的转换需要考虑的因素包括：
    - 相机pose的影响
    - 接地点
    - 稳定性
  - 第二是时序信息计算，主要是针对跟踪处理，需要注意以下几点：
    - 对相机帧率和延时有要求，要求跟踪必须是一个轻量级的模块，因为检测已经占据大部分时间
    - 充分利用检测模型的输出信息（特征、类别等）进行跟踪
    - 可以考虑轻量级Metric Learning
  - 第三是多相机的环视融合
    - 相机布局决定融合策略，要做好视野重叠

### 红绿灯感知

深度学习进行红绿灯感知模块的构建，主要分为以下几步：

- 第一是相机选择和安装
  - 相机选择需要注意几个重要的参数
  - 一是相机的高动态比HDR要高于100db
  - 二是拍摄图像的分辨率要达到1080P，满足15pixel大小的灯能够看得到
- 第二是高精地图的交互
  - 我们并不是把所有红绿灯识别算法都交给在线算法完成，这样做无法满足鲁棒性要求也加重算法负担
  - 需要把一些固定信息交给高精地图去完成，算法只实现在线变化的一些因素
- 最后使用深度学习识别灯颜色的变化
- 实际使用过程中可能会更复杂，需要把对应关系匹配起来，需要做3D到2D的投影

### Radar感知

- Radar的点云信号投影的成像存在很大的噪音，需要进行鉴别
- 因为金属的反射信号比较好，对路边界金属栅栏的感知结果是一条明显的、由许多点组成的线，基于该特征，可以用Radar反射信号来做高速路道路边缘栅栏的检测

### 超声波感知

- 超声波只能进行近距离感知，并且无法感知具体的位置
- 对无人驾驶来说，行驶过程中帮助并不大，更多的是用于倒车和特别近距离的感知

### 机器学习与感知

- 机器学习里面存在一个普遍的假设，训练集和测试集是独立同分布的，如果测试和训练没有任何关系，测试效果是没有任何保证的
- 但是无人车感知的训练集是封闭的，而测试集是开放的
- 测试是在开放道路进行的，如果遇到新的障碍物，在训练中从来没见过，难以处理
- 在城市道路上很少见到卡车，但是高速会遇到很多卡车，而且卡车上的东西也很多，如果机器学习模型没见过这些障碍物，很有可能带来一些错误
- 无人车的安全需要可解释，出现一个Bad case需要说清责任，需要搞清Bad case是由什么原因导致的，以便改进
- 在感知模块中，除了做基本的检测、分割之外，还有后处理阶段等由公式表示的几何计算问题，是不需要深度学习的
- Common sense也不需要深度学习，而且深度学习的效果不好
- 如果数据量小，特征很难从原始数据学习，深度学习的效果可能就受到影响，因此诸如SVM或者随机森林这些机器学习算法，可能需要结合场景选择

### 感知的未来发展

- 如果在自动驾驶的研究中，发现某一类传感器在感知或者其他模块中具有很大的价值。那么，整个资本市场会投入很多人力、财力研发传感器。随着量产之后，传感器的成本就会大幅下降，更新换代就比较快。
- 深度学习已经证明了在感知中有很大的作用，但是计算量很大，专门研究车载AI芯片是对这一问题的很好解决方案。
- 现在很耗时的CNN模型以后都不是瓶颈，而且定制AI芯片的功耗可以足够低，满足车载需求。深度学习需要大量数据的问题，可以通过仿真来弥补
- 点云仿真相对简单一些，图像仿真相对困难点
- 如果仿真这条路可以走通，那么仿真+深度学习不断循环迭代，是非常有前景的
- 目前，自动驾驶都是在车上安装传感器进行感知，感知的范围、鲁棒性都有待提高
- 如果将这套传感器布置在道路上、灯上，让它们来感知，然后将实时结果传输给无人车，如果车上的传感器失灵，那么路面上的传感器会告知无人车障碍物信息，保证系统安全性